<html>
  <head>
    <meta charset="utf-8" />
    <link rel="stylesheet" href="styles.css">

  </head>
  <body>
  <!--    <script type="text/javascript" src="https://cdn.jsdelivr.net/pyodide/v0.26.0a4/full/pyodide.js"></script>-->
<!--  <script type="text/javascript" src="https://ryanking13.github.io/pyodide-pygame-demo/dist/pyodide.js"></script>-->
  <script type="text/javascript" src="custom_pyodide/dist/pyodide.js"></script>

    <script type="text/javascript">
      async function main() {
        let pyodide = await loadPyodide();
        await pyodide.loadPackage("micropip");
        const micropip = pyodide.pyimport("micropip");
        await micropip.install("dist/morl-0.0.1-py3-none-any.whl");
        await micropip.install("gymnasium");
        await micropip.install("tqdm");


        // await micropip.install("opencv-python")
        // await micropip.install("flask")
        // await micropip.install("scipy")
        await micropip.install("asyncio")
        await pyodide.loadPackage(["pygame-ce"], { checkIntegrity: false })
        canvas = document.getElementById("canvas");
        pyodide.canvas.setCanvas2D(canvas);

        pyodide.runPythonAsync(`

import gymnasium as gym
import io, base64

from gymnasium.envs.registration import register
# import cv2
from js import document
import time
from asyncio import sleep

from models.scalar_morl import MO_Qlearning, MO_EpsilonGreedy, MO_LinearQlearning
import numpy as np
import json
from experiments.flp.tabular_lifecycles import vis_run, tabular_mo_state, get_features
from experiments.flp.flp_exp_1__tabular import simple_morl_reward_fn
from experiments.flp.utils import get_flp_env
from functools import partial
from experiments.flp.params import Params
from pathlib import Path
import importlib.resources
from importlib.resources import files


def setup_learning_and_explorer_code(qtable, params):
    learner = MO_LinearQlearning(
        learning_rate=params.learning_rate,
        gamma=params.gamma,
        state_dim=[params.state_dim, params.state_dim],
        action_size=params.action_size,
        reward_dim=2
    )
    explorer = MO_EpsilonGreedy(
        epsilon=params.epsilon,
        seed=params.seed,
        scalar_vector=[1, 1]
    )

    print(qtable[0][0].shape)
    learner.set_qtable(qtable)
    return learner, explorer

params = Params(
    total_episodes=2000,
    max_episode_len=None,
    learning_rate=0.4,
    gamma=0.99,
    state_dim=6,
    epsilon=0.1,
    map_size=4,
    seed=123,
    is_slippery=False,
    n_runs=20,
    action_size=None,
    state_size=None,
    proba_frozen=0.5,
    proba_coin=0.4,
    proba_hole=0.1,
    eval_total_episodes=10,
    eval_freq=100,
    savefig_folder=Path("../../_static/img/tutorials/"),
)

map_size = params.map_size

env = get_flp_env(params, params.map_size, render_mode="human")

qstr = files('models.checkpoints').joinpath('demo_qtable.json').read_text()
qtables = json.loads(qstr)
qtable = [[np.array(x[0]), x[1]] for x in qtables]


while True:
    if not map_size:
        map_size = params.map_size
    params = params._replace(action_size=env.action_space.n)
    params = params._replace(state_size=env.observation_space.n * map_size * 2)
    params = params._replace(map_size=map_size)

    learner, explorer = setup_learning_and_explorer_code(qtable, params)
    explorer.eval = True

    state = get_features(env.reset(seed=params.seed)[0],  shape=params.state_dim)  # Reset the environment

    step = 0
    done = False
    total_rewards = 0

    while not done:

        # uncomment in the index.html code
        speed = document.querySelector('#speed').value
        await sleep(1 / int(speed))
        goal_scale = int(document.querySelector('#gqfunc').value) / 100
        cookie_scale = int(document.querySelector('#cookiesqfunc').value) / 100
        scalar_vector = [goal_scale, cookie_scale]
        explorer.update(scalar_vector=scalar_vector)

        action = explorer.choose_action(
            action_space=env.action_space, q_values=learner.action_values(state)
        )

        # Log all states and actions

        # Take the action (a) and observe the outcome state(s') and reward (r)
        new_state, raw_reward, terminated, truncated, info = env.step(action)
        # new_state = tabular_mo_state(new_state, map_size=params.map_size)
        new_state = get_features(new_state, shape=params.state_dim)


        reward = simple_morl_reward_fn(raw_reward)

        done = terminated or truncated

        total_rewards += sum(reward) if isinstance(reward, list) or isinstance(reward, tuple) else reward
        step += 1

        # Our new state is state
        state = new_state
    explorer.eval = False


      `);

      }
      main();
    </script>
    <div class="img_container">

  </div>
  <div class="demo-content">
    <canvas id="canvas" width="600" height="500"></canvas>
  </div>

  <div class="slidecontainer">
    <label for="speed">Speed:</label>
    <input type="range" min="1" max="100" value="1" class="slider" id="speed">
  </div>

   <div class="slidecontainer">
    <label for="speed">Goal Q-Function:</label>
    <input type="range" min="0" max="100" value="100" class="slider" id="gqfunc">
   </div>

  <div class="slidecontainer">
    <label for="speed">Cookies Q-Function:</label>
    <input type="range" min="0" max="100" value="100" class="slider" id="cookiesqfunc">
  </div>
  </body>
</html>